
        <html>
            <head>
                <style>
                    body { font-family: Arial, sans-serif; margin: 0 auto; max-width: 1200px; }
                    table { width: 100%; table-layout: fixed; border-collapse: collapse; }
                    th, td { padding: 10px; vertical-align: top; word-wrap: break-word; border: 1px solid #ddd; }
                    th { background-color: #f2f2f2; font-weight: bold; }
                    .correction { background-color: yellow; }
                    h1, h2 { padding-top: 50px; margin-bottom: 0; }
                    .chapter { page-break-before: always; }
                    .content { white-space: pre-wrap; word-wrap: break-word; font-family: Arial, sans-serif; margin: 0; }
                </style>
            </head>
            <body>
        <table><tr><th>Original Chunk</th><th>Corrected Chunk</th></tr>
                    <tr>
                        <td><div class='content'>Preface

Thank you to ...

Intro about Intility (MAX 0.5 PAGE)

</div></td>
                        <td class='correction'><div class='content'>Please provide me with the paragraph to review and edit.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Glossary

Data jobs

DBT docs

Business system

Reports/models

Exposures

Mart

Staging

Source

WAN

WCAG

Bifrost

Intility standard

SSMS 18 (SQL Server Management Studio 18)

</div></td>
                        <td class='correction'><div class='content'>There are no grammar or structural errors in this text. It is a list of terms without any sentences to correct. Therefore, it is good as it is.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Introduction

In today's data-driven world, organizations rely heavily on data to make informed decisions. However, managing and documenting data can be a complex and time-consuming process. In response to this challenge, our team has developed a data documentation tool aimed at simplifying the documentation process for data jobs.

This tool is designed to help data professionals track and document data transformation processes, provide an overview of data dependencies, and facilitate collaboration and knowledge sharing among team members leading to increased efficiency and productivity. In this report, we describe the design and implementation of our data documentation tool and provide an evaluation of its effectiveness in a real-world setting.</div></td>
                        <td class='correction'><div class='content'>Introduction:

In the present data-driven world, organizations rely heavily on data to make informed decisions. However, managing and documenting data can be a complex and time-consuming process. In response to this challenge, our team has developed a data documentation tool aimed at simplifying the documentation process for data jobs. 

This tool is designed to help data professionals track and document data transformation processes, provide an overview of data dependencies, and facilitate collaboration and knowledge sharing among team members, leading to increased efficiency and productivity. In this report, we describe the design and implementation of our data documentation tool and provide an evaluation of its effectiveness in a real-world setting.

Comments: 

- The paragraph is correctly structured and free of grammatical errors.
- The modification made is just a minor punctuation correction in the first sentence to make it grammatically correct.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Domain

To ensure a shared understanding for this thesis, it would be helpful to clarify terminology and concepts, which we will do in the following subchapter.

Data science



Data science is a field which involves using statistical and computational methods to extract insights from large and complex datasets. It combines computer science, mathematics and statistics, machine learning and advanced analytics to identify patterns and relationships within the data (Kelleher & Tierney, 2018). The goal of data science is to use data-driven insights to make better predictions and decisions.

Data scientists are responsible for a range of tasks, such as data cleaning, preprocessing, analyzing, and visualizing, as well as building predictive models using various machine learning algorithms (Gardner, 2021). To be successful, data scientists need to have good problem-solving, critical thinking, and communication skills to develop data-driven strategies and explain their findings to stakeholders.

The importance of data science is increasing in many industries, including healthcare, finance, and marketing, due to the exponential growth of data collection. This has led to a rapid expansion in the field of data science, which again calls for useful and user-friendly tools for documentation.



The current solution – DBT and DBT docs



The employees in Intility’s data science department use DBT (Data Build Tool) extensively in their daily tasks. DBT is a tool that helps build, test and maintain data pipelines. It provides features for testing, automatic documentation generation, modularity, and version control, making it easy to collaborate and manage changes. (Barcheski & Collis, 2023)

In addition to building and maintaining data pipelines, DBT also provides a feature called DBT docs. This feature automatically generates a website containing documentation for your DBT project, including information on models, sources, and tests (See example in Figure X.X). With DBT docs, you can easily keep your project's documentation up to date, collaborate with team members, and provide a source of truth for your data pipeline. Another feature within the website is a lineage graph, visualizing the data pipeline inside of DBT (Figure X.X).
By using DBT and DBT docs together, you can create a robust, maintainable, and well-documented data pipeline that is ready for analytics and reporting.

Manifest.json



The ‘Manifest.json’ file can be exported from DBT docs and contains all the information about how the data is organized and transformed in the DBT project. This includes information about models, sources, and tests, as well as their relationships and dependencies. An example of such metadata can be the name, id, file path, type, description and dependencies of an exposure. This information can be used to get a better understanding of what data the exposure contains and how it is affected by other data.
In our project we will use the information in the manifest file to build a custom documentation tool which displays the data pipeline, where the data comes from, how it's transformed, and what the final output looks like.</div></td>
                        <td class='correction'><div class='content'>Overall, the paragraph is well-written and clear. Here are some small edits:

- In the first sentence, change "which" to "that" for better clarity.
- Combine the second and third sentences into one sentence for better flow: "It combines computer science, mathematics, and statistics, machine learning, and advanced analytics to identify patterns and relationships within the data, with the goal of using data-driven insights to make better predictions and decisions."
- In the fourth sentence, add an article before "data collection": "due to the exponential growth of the data collection."
- In the fifth sentence, change "modularity" to "modularization" for better clarity.

Apart from that, everything else looks good. Keep up the good work!</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Objective

The main objective of this project is to create an easy-to-use application for documenting data jobs. The application should function as a substitute for the existing documentation solution (DBT docs) and have extended functionality to fit the needs of Intility’s employees in the data science department. Our application should also include the functionality to display information about business systems, and the relationship between business systems and sources.

A key issue Intility has with the existing solution is that there are no opportunities to develop further functionality. Since the applications used today are not made by Intility, they do not have the option to change layout, change existing functionality or implement new features. Opening for such an opportunity would be very helpful to further increase automation in Intility’s data science department.</div></td>
                        <td class='correction'><div class='content'>Overall, the paragraph is well-written and structured. However, there are a few small changes that could be made:

1. Instead of "function as a substitute," use "serve as a replacement for" to sound more professional.
2. Instead of "the functionality to display," use "functionality for displaying" to make the sentence flow better.

Here's the corrected version: 

Objective

The main objective of this project is to create an easy-to-use application for documenting data jobs. The application should serve as a replacement for the existing documentation solution (DBT docs) and have extended functionality to fit the needs of Intility’s employees in the data science department. Our application should also include functionality for displaying information about business systems and the relationship between business systems and sources.

A key issue Intility has with the existing solution is that there are no opportunities to develop further functionality. Since the applications used today are not made by Intility, they do not have the option to change the layout, modify existing functionality, or implement new features. Opening up such an opportunity would be very helpful to further increase automation in Intility’s data science department.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Group background

Competence



This report introduces a group of four bachelor students who are all enrolled in the ‘Programming’ study program at NTNU in Gjøvik. Throughout the program, the students have acquired skills and knowledge about a variety of programming subjects. We have experience working in a group from previous projects throughout their education, which was a major reason why we chose to come together to write our bachelor thesis.

In the figure below is a table containing the relevant courses from the program, with a short explanation of their relevant learning outcomes.

Choosing the task



In the initial phase of the project, our main goal was to find a suitable task that would allow us to apply the knowledge and skills we have acquired throughout our studies. Among the suggested tasks from the university, we saw three tasks from Intility, all of which were interesting. To apply for these tasks, we sent an application letter that included our CVs and grades from all previous courses. After two interviews, we were offered the opportunity to work with Intility.

We accepted the offer, as we found the task to be remarkably interesting and helpful to the company. We especially liked that it was an application which provided real value to the data science department, would be frequently used, and that would be developed further after our time at Intility was over.
The agreement included that the group would develop the data platform manager this report is based on. Intility would provide the necessary equipment, train tickets and commute housing every two to three weeks. We have described the work environment and collaboration with the company further in chapter X.X.</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Constraints

The constraints of a project can play a critical role in shaping the direction of the work and its outcome. In the case of our bachelor thesis, we faced a range of constraints that influenced the development of our data documentation tool. These constraints were both internal and external and affected various aspects of the project. In this chapter, we will explore the constraints we faced and how we managed them to achieve our project goals.

Time



This assignment was large, and Intility did not expect us to finish the application with the given time. The application had limitless potential for further development, which meant that we had to set clear delimitations of what should be prioritized. The whole project, including writing the project report should take between 560 and 660 hours per student.

To manage this constraint, we decided not to create tests for every part of the code, but instead create good tests for the main functionality. This was to show that we have the knowledge and skills to create good tests and could have created tests for all functionality if time was no constraint.

Access to sensitive information



Access to Intility’s internal information about customers and employees was another constraint. Firstly, we did not have access to a database to retrieve employee names to have options when selecting owner and contacts for new business systems. After dialogue with Intility, we produced a solution to store the previous used name which had to be added manually. This will be fixed when Intility take over the application development.

Secondly, we did not have access to the endpoint which let us access an updated manifest.json file. This introduced a problem in the early stage of the development due to information from the updated manifest file which we did not have access to. The final product also did not have automatically updated information due to this constraint. The functionality to update the database based on a new manifest file is implemented, but for now the user has to manually change the existing file.

Technical expertise



Technical expertise can pose a significant constraint in the development of the data documentation tool. Although we have obtained a strong foundation in computer science throughout our studies, the development of a complex tool like this requires advanced technical knowledge and expertise. The tool requires the integration of various data sources, such as business system information, reports, and automatically generated documentation from DBT. This will again require knowledge about DBT, DBT docs and the entire data science field, which we have little to no experience with.

Furthermore, the tool should be coded using Intility’s preferred languages, namely TypeScript and C#, which are also relatively new to everyone in the group. To achieve the objectives of this project, we need to first acquire the necessary knowledge and skills within these technologies.

Practical and physical



Effective communication within the team is essential for a successful software development process. The physical distance between the team members and Intility was another hurdle we had to manage. With the use of several digital communication tools, we were able to keep the close collaboration with the company during the entire development process. We as a group are well familiar with this method of communication due to the Covid-19 lockdown. More information about the digital communication tools we used can be found in chapter . It was important that we had descriptive issues in Jira, and that everyone on the team updated the issue board so there were no one working on the same issues.

Other than the physical distance, there have not been any other practical constraints related to our work. Everyone on the group got a laptop and the necessary equipment to work as efficient as possible both at the office and at home. Intility provided us with all the needed software, hardware, our very own office spaces, and the access to meeting rooms.

Intility also covered lunch at the office and any travel costs related to the commute. The employees at Intility have done everything they can to ensure that we have had good conditions to work on this project.

</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Delimitations

As mentioned, the main objective of the project is to make a data job documentation tool, however there are delimitations regarding what should be implemented in the final product.

Only documenting functionality will be within the scope of this project. This means we will not implement functionality which has a direct impact on the data jobs, but rather documents information about each stage of the data pipeline. The application will not have functionality to trigger or re-run data jobs, however, we should leave this as an opportunity to expand for the company at a later stage.

The finished product will feature user authentication, however individual user roles like admins, readers and developers will not be part of this version of the application. This feature can be added at a later stage. We are not provided with the privileges necessary to obtain information about individual employees whenever they are logged in to our application.

</div></td>
                        <td class='correction'><div class='content'>lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Project goals

In this project, our primary objective is to achieve a set of specific goals that will help us accomplish our overall task. Our goals are divided into three different categories: result goals, effect goals and learning goals. Result goals focus on the results we wish to achieve, while effect goals concentrate on the impact our project will have on the intended audience. Learning goals center on the new knowledge and skills we hope to acquire during the project. With a clear understanding of these goals, we can effectively plan, execute and evaluate our project to ensure its success.

Result goals



The result goal of our project is to create an application capable of displaying all relevant information about a data job and its pipeline. This will be achieved by tying together automatically generated documentation from DBT with business system information and reports. In addition, we aim to include a feature displaying a visual representation of the relationships between various parts of a data job, while ensuring that the loading time of the visual representation is no more than 50% of DBT docs’ alternative. Lastly, we intend for the application to automatically update its saved information once every 24 hours.

Effect goals



Increased adoption and usage of the data documentation tools outside of the Data Science department, resulting in increased overall understanding and collaboration across teams.

Increase accessibility of information and ease of information gathering in terms of more forgiving search parameters.

Ensure that data in the system is accurate and reliable by tracking changes made.

Reduce the loading time for large lineage graphs.

Design which complies with WCAG and Intility’s brand.

Learning goals



Another important aspect of our bachelor thesis is learning goals. The goals below are what we expect to learn through conducting and concluding this bachelor thesis. The group would like to acquire more experience and knowledge of the following:

Agile development and Scrum in order to have an effectively workflow on the project.

Git best practices, version control and CI/CD (continuous integration & continuous deployment).

Azure and cloud platforms to host an application.

Managing a larger project with deadlines for delivery.

Become confident in .NET and Typescript and SQL for data management and documentation tasks.

To learn more about how to collaborate with a company to develop a useful application that meets their needs.

Making an application within an unfamiliar domain like Data Science.

</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Target audience

Application



The primary target audience for our application is individuals who work in the data science department of Intility. This includes data scientists, data analysts, and data engineers who require an intuitive and user-friendly tool to analyze large and complex datasets efficiently. However, the application may also be used by other employees at the company who work with data but do not have a specialized data science knowledge. These include departments such as finance or marketing, that can also benefit from using the application to analyze data relevant to their areas. The tool is designed to simplify the data analysis process enabling users to gain a better understanding of it. To summarize, the application is valuable for anyone working with data at Intility, regardless of their level of expertise.

Report



The target audience for our report is primarily educators and evaluators. The report provides an in-depth analysis of the development process and implementation of our data platform manager. It covers the relevant information needed for someone reading to understand how the application is implemented, our development process and other relevant information. In addition to educators and evaluators, our report may also be of interest to students. The report can be valuable for students wanting to learn more about creating or learning more about data analysis tools. Overall, our report is a comprehensive and informative resource that offers insights into the development and implementation of our data platform manager, making it a valuable resource for a wide range of individuals.

</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Requirements

The requirements chapter outlines the specific needs and expectations for the data documentation tool developed as part of our bachelor thesis project. By defining these requirements, we aim to ensure that the tool effectively meets the needs of its target users, mentioned in chapter X.X.

This chapter covers the functional and non-functional requirements of the tool, including its desired features, performance specifications, and usability guidelines. We have identified these requirements through extensive research, meeting with the target users, analysis of existing data management tools, and research around the industry best practices. The resulting set of requirements provides a clear roadmap for the development and evaluation of the tool, ensuring that it meets the needs and expectations of its users.

This chapter covers the functional and non-functional requirements of the tool, including its desired features, performance specifications, and usability guidelines. We have identified these requirements through extensive research, including interviews with potential users, analysis of existing data management tools, and consideration of industry best practices. The resulting set of requirements provides a clear roadmap for the development and evaluation of the tool, ensuring that it meets the needs and expectations of its users</div></td>
                        <td class='correction'><div class='content'>Lgtm! However, to improve the clarity of the second sentence, here is a suggestion:

"We identified these requirements through extensive research, which included conducting interviews with potential users, analyzing existing data management tools, and considering industry best practices."</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>UML Class diagram

The class diagram shows the structure of the domain and the software requirements needed. It describes the systems entities and their relations which helped gain understanding of the problem area. It was also helpful when creating the logical model and data classes in the code used in the API.



In the image above one can see that the manifest contains many “data models” which is a xxxx. This means a specific data model can be either be one the four classes which inherit it. This was not in the original domain model which only contained the subclasses. Figuring this out early meant that normalization was easier when creating the logical model.</div></td>
                        <td class='correction'><div class='content'>In the image above, one can see that the manifest contains many "data models," which are a part of a hierarchy. This means that a specific data model can be one of the four classes which inherit from it. This was not illustrated in the original domain model that only included the subclasses. By detecting this feature early on, normalization became more manageable during the creation of the logic model. 

Comment: Clarified the sentences to be more concise and easier to read.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Functional requirements

Use-case diagram



The use case diagram shows how the different actors can interact with our system and the functionality it provides. The diagram doesn’t give much detail but gives us a list of requirements that the system needs. This helps in creating the system and getting a common understanding of what the system needs, which was difficult at the beginning of the project.





Actors



Regular user: A regular user will have the possibility to inspect all data assets and metadata. The lineage graph will provide an overview and relations between business systems and data. The user will not be able to make any changes that can impact other users or the system outside of their own view.

Data Scientist: A data scientist will have all the functionality of a regular user. As well as the possibility of adding or deleting business systems and linking them to data sources. The admin user will also be able to add or delete business glossary definitions.

Descriptive use-case



An example of a detailed use case to show ideal flow of execution.

</div></td>
                        <td class='correction'><div class='content'>Lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Non-functional requirements

Non-functional requirements specify the characteristics and performance needs of a system. These requirements we have divided into five categories: availability, reliability, resilience, scalability, and security. By specifying these requirements, we know what we need to develop towards, but also what we don’t need to prioritize. If the system isn’t going to grow in users, functionality or data, there is no reason to prioritize testing and potentially refactoring for a much larger scale.

Availability



After discussions with the product owner and the data science team it was clear that availability of the program would be especially important during business hours and preferably in the evenings. An agreement was made that nighttime would be the time to update our system with new metadata and changes made in the data catalogue. We therefore landed on an availability percentage of 99 which gives us roughly 15 minutes each day of downtime for updating and service downtime.

Reliability



Since the system gives an overview of much of the company’s data, an important factor is the reliability to trust that the system’s information is correct and functional. Errors in data and dependencies between data can be an issue as it may give users wrong information resulting in bad business decisions and lost work hours. This is especially important as the system grows and expands functionality as described later in the further work chapter. This meant that extra focus had to be put on testing the functions and logic which read and update metadata to ensure reliability. Therefore, we aim to perform integration and unit testing on the most crucial functionality as well as user testing.

Maintainability



“Maintainability refers to the ease with which you can repair, improve and understand software code”. The software built during this project is going to be iterated on and added features to. As stated earlier in xxx, the ambition of this project long term to also be used for scheduling and monitoring data jobs. Maintainability is not an easy thing to measure and can be quite subjective, but the objective is to write readable code without unnecessary complexity.

Write about static code analyzer “SonarQube” and refer to this chapter.



Scalability



Write about how many users at launch

How many users in the future

In terms of scalability a bigger concern than the number of users involved is the issue of the application to more data. Each week since the start of the project more metadata has been added and this can create problems which do not exist at this size. Therefore, we need to test for large data changes in our integration tests and monitor the speed of API closely. An API request with a response time of 2 seconds might be good enough at the current size, but not in the future.

Security



This application’s purpose is as an internal business tool for employees and potentially customers. Users outside of these constraints should not be able to use the application. To solve this issue, the system will use user-authentication for both the front-end and the API.

The use-case diagram showed the two users: regular user and admin user, where the regular user only has READ privileges while the admin user also has POST, UPDATE and DELETE privileges. The authentication will need to differentiate between the two and limit the regular user’s options. You can read more about this in the API design and controller design chapter.

The report will cover specific security measures in the relevant chapters.</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Design

Bifrost

DBT docs vs DPM

How DPM design compares to other Intility applications

Refer to images within the implementation chapter to show the design

</div></td>
                        <td class='correction'><div class='content'>The paragraph seems to be a list of topics for discussion. Therefore, I suggest the following corrected version:

- "Design" is a vague heading, please be more specific about the design aspect that will be discussed here.
- I assume "Bifrost" is a specific tool or platform. Please provide more context and explanation about it.
- "DBT docs vs DPM" needs to be clarified further. What are the differences and similarities between DBT docs and DPM? What is the purpose of this comparison?
- "How DPM design compares to other Intility applications" is a good topic, but it needs to be more specific. What are the other Intility applications? How does the DPM design compare to them? 
- It's a good idea to refer to images within the implementation chapter to show the design. Please make sure those images are clear and relevant to the discussed topics.

Overall, the paragraph needs more context and explanation to provide a comprehensive and informative resource.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>GUI

Design:

The design of the Data Platform Manager utilizes Intility’s React library Bifrost, which offers a wide range of pre-built components and utilities that allow for the creation of responsive and scalable web applications. One key advantage of this library is its built-in coloring system, which adheres to the WCAG guidelines. This makes Bifrost the ideal choice for developers, as it drops the need to fully consider these guidelines when using other libraries, such as React Bootstrap. Moreover, since all applications and websites of Intility share the same styling foundation, it makes sense to use Bifrost in this case. By utilizing a familiar and widely used library, the development process of the Data Platform Manager becomes more streamlined and efficient. Furthermore, it ensures consistency with the existing applications and websites within the organization.

The frontend design for the data platform manager follows a standard layout that is optimized for a good user experience. The layout consists of a top-bar, navigation-bar on the left and a main body with content. They are set up as follows:

Top bar: The top bar includes an Intility logo, name of the application and on the right in the top bar there are two buttons. One button is for the user’s profile and the other to change between light and dark mode.

Left side navigation-bar: The left side navigation-bar has four main categories, overview, data catalog, data consumers and help. Overview links to the main page, the others have under-categories that link to the specific content.

Main body: The main body displays the content depending on which page that is navigated to.



For a good user experience the website is deigned to be as user friendly and intuitive as possible. First off it uses font size and icons following WCAG. Icons are made and used to be easily distinguishable. Another example is when the website is under a certain width the left side navigation bar will be hidden under a dropdown menu. This will make it more appealing for users with smaller screens so that they will be able to see the main content just as good as those with a larger monitor. Lastly, the sidebar contains dropdown menus for each of the main categories that can easily be opened. With this feature, users can find the information they need without having to spend too much time searching for it, making their browsing experience more enjoyable. Overall, the application uses a very minimalistic design that eliminates clutter and distraction making it very user friendly and simple to navigate.



As mentioned earlier the data platform manager adheres to several WCAG guidelines to ensure that it is accessible to a wide range of users, including those with disabilities, and offers a good user experience.  WCAG 2.2 Guideline 1.4 is met using font sizes and icons that adhere to the guidelines, ensuring that users can easily read and comprehend the content of the website. WCAG 2.2 Guideline 1.3 is met by providing alternatives for non-text content using easily distinguishable icons, making the website accessible to users with visual impairments. The built-in coloring system of Bifrost adheres to WCAG 2.2 Guideline 1.4.3, ensuring that the color contrast between text and background meets the minimum requirements, making it easy to read for everyone. The website structure meets the WCAG 2.2 Guideline 1.3.1 by organizing the content into a top bar, left-side navigation bar, and a main body. This ensures that users can easily understand the structure of the website, find information they need, and navigate efficiently. WCAG 2.2 Guideline 1.4.11 is met using components with contrasting colors, ensuring that users with color blindness can easily distinguish between them. Finally, WCAG 2.2 Guideline 1.4.10 the left-side navigation bar is hidden into a dropdown menu on smaller screens making it so that users do not have to scroll or zoom in to view the content.

</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>System design

In the GitLab repository, there are two folders, one for frontend and the other for backend. All the group members had access to both folders to work on both backend and frontend. It was important to have a good structure of both the frontend and backend folder. The reason behind this is there is someone else at Intility that will take over the project after this bachelor's degree. Looking at the structure of other Intility applications was important in order to make this process as easy as possible for the next development team.

Backend system design



Backend is structured in a way with a folder for each of the following: controllers version one, data, models, integrations tests and unit tests. All the folders are connected to each other where it is needed to use models or other related code from another folder.

The controllers folder consists of all the controllers which are handling the logic for the different endpoints. Some controllers have more than one request, this is because the endpoints are related to each other, or they have two different uses within the same endpoint. Figure xxxxxx below shows what a controller with different requests looks like in the Swagger tool mentioned in the technologies section. Each request in the controller is commented with response code which will give the user an indication if there is anything wrong. For example, if the response code is 500, then there is an internal server error.

The data folder is where all functions that are used in the controllers are located. There are functions to handle functionality related to updating and fetching information from the database. These functions handle the logic when a request is sent from frontend. There are also some functions which check the input from frontend before the database is populated with latest information. It is important to check for invalid input before the database is populated, even though there are checks for valid information frontend. This is to prevent SQL-injection if the user is not sending a request directly from frontend, but with the use of tool like Swagger or Postman.

Within the data folder, there is a manifestupdate folder

The models folder consists of classes of the structure. There are dto classes and regular classes. The dto classes are data transfer objects which are used to transfer data without updating the database. The regular model classes are used to update the database with the given information. There are also some minidto classes which are smaller sections of the dto classes used to reduce redundant information in the requests if the development team were to use the same data.

Integration test folder

Unit test folder is where all code related to testing of the different functions used in the different endpoints.



Figure(xxxxx)







Frontend system design





Frontend is organized using a modular folder structure that includes several key folders that organize the different types of files used in the application. One of these directories is the “Assets” folder, which houses static files such as images and logos used throughout the application.

Another folder is the “Auth” folder, which contains all files related to authentication, such as login and authorization of users. It also includes a function for fetching data from the API with extra security authentication.

One of the most important folders in the frontend application is the “Components” folder. This folder stores reusable UI components that can be used across multiple pages and features. The use of reusable components helps to ensure consistency in the user interface and saves development time by avoiding the need to build the same UI elements from scratch for each new feature or page.

The components in the “Components” folder are organized according to how the sidebar of the website is listed. For example, the “Data_Catalog” folder holds all components related to that category such as “Data_Assets”. This organization is done to improve code organization and maintainability.

In addition to the component directory, there is a “Pages” folder that consists of the actual pages of the application, which may be composed of multiple components. This folder helps to keep the pages organized and easy to find.

Furthermore, there are three more folders: “Tests”, “Types” and “Utils”. The "Tests" folder contains files related to automated testing of the application. Tests are important for ensuring that the application works correctly and meets the desired requirements. The "Types" folder contains files that define and standardize the types and interfaces used throughout the application. One example is types for the API responses. The "Utils" folder contains utility related functions and configuration files.

Finally, there are files related to the setup and initialization of certain things, such as routing and test setup. These files are crucial for ensuring that the application is properly configured and set up before it is run.



Help

</div></td>
                        <td class='correction'><div class='content'>In the sentence "Within the data folder, there is a manifestupdate folder", it is not clear what the "manifestupdate" folder is for. The sentence could be improved by adding more context or a brief explanation of what the folder is for.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Technologies

The development team chose to use the standard technologies they use in Intility. There are several reasons for this which will be enlightened in this chapter, but the main reason is that the group wanted to create a product which could be useful for a company like Intility. It was also important to use tools technologies that Intility use. This will make the further development of the product possible with just minor changes to our application.</div></td>
                        <td class='correction'><div class='content'>The development team chose to use standard technologies used in Intility. There are several reasons for this, which will be elaborated upon in this chapter. The primary reason is that the group aimed to create a product that would be useful for a company like Intility. Additionally, it was important to use the same tools and technologies that Intility employs. Doing so would allow for further development of the product with only minor changes to its application. 

Comments: 
- Reworded sentence structure for clarity and conciseness. 
- Added "elaborated upon" to avoid repetition of "enlightened."</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Backend

At the start of this project, the development team chose to use .NET for the backend development which is an object-oriented programming language designed by Microsoft. .NET is a language which is great to use with Web Api support and perfect for this assignment.

There are no problems with connecting the application to frontend and other external systems such as Azure. In one of our previous courses called “Integrasjonsprosjekt”, we struggled a little bit on connecting the frontend to backend and to make the website safe enough to have https. This was not a problem we encountered with this project due to better choice of backend technologies.

Another reason to use .NET is how easily it can be integrated with Swagger which we have used to manually test the endpoints. The figure xxxxx in chapter 5.2.1 () shows an example of how a controller for the endpoints look like. To use swagger, we had to authenticate with our Intility. The backend swagger was running at all time with the code pushed to Gitlab, bit we could also run the backend locally and check if the code worked as intended with localhost swagger. This was to ensure that the code pushed to Gitlab could run without any problems.



(https://ukad-group.com/blog/aspnet-core-8-pros-and-cons/)

The current application takes some time to load because it has a lot of information, therefore it is important to choose a programming language which runs fast and efficiently. As mentioned in chapter 3.7.1 () and in chapter 3.7.2 (), our goals was to decrease the loading time for both the dbt docs and for the lineage graph. A possible solution to this was a fast backend which could cache large amounts of data ensuring that the load time will be faster after the first time opening the website.







()

Alternatives to .NET:



Python is an alternative to .NET the development team could have used. There are some teams at Intility that are using python, but compared to .NET, python is not that good at handling high-performance computing, and it is not the best language for processing substantial amounts of data. ().

Golang is a familiar language which is like .NET, but it is a simpler language and has fewer features than .NET. Features like LINQ and pattern matching are not supported in Golang. (https://cshark.com/blog/c-vs-go-which-is-better-for-your-next-application/) LINQ is a fantastic addition to a language which supplies a consistent query experience to relational databases. ().

Java is one of the most widely used programming languages for development. There are a lot of reasons why java is well suited for the software industry. For instance, Java can run on any operating system with its compilers and Java Runtime Environment. That does not apply to .NET which only focuses on Windows users. This did not matter for the development team, because the application will be developed on computers with Windows and when the application is pushed to production, it can also be used by users without Windows.

A reason to decide on .NET instead of Java is because the development team are more familiar with Visual Studio as an IDE compared to IntelliJ which is the most used IDE for Java. This is not a huge reason, because most IDE’s are very similar, but we found it more suitable to go with the familiar IDE. This topic will be discussed in chapter 6.1.3 (). ()

All the three languages are exceptional for web and cross-platform development, but we did not find any other reason to why we should deviate from the standard Intility backend language.



Manually testing the endpoints



In order to test and develop the backend endpoints before trying them frontend, the development team have used swagger. The advantage of Swagger is that you can quickly test the API as it creates documentation, example requests and data from the code. In the development phase this is a useful tool to keep the cost of change low. The development team could also have used Postman for the manual testing of the endpoints, but Swagger is well integrated with the verification tokens (bearer tokens) which are needed to get the correct response from the database.

Backend compilators



The compilers used for this project are both Visual Studio Code and Visual Studio 2022. The reason behind this is different preferences within the group. There are several purposes with using Visual Studio 2022 and Visual Studio Code instead of, for example other compilers like IntelliJ. The main reason the development team are more familiar with Visual Studio.

It was also the preferred from Intility that we used either of the two compilers in order to make it as easy as possible to integrate the application with Intility’s existing applications. This is because the other developers at Intility use these compilers and all the systems they used are integrated with the two compilers. Another reason was that they could offer more help if that was needed.

Backend testing tool



xunit



Database tool



The database tool used for this assignment is Microsoft SQL Server Management Studio 18, which is a graphical integrated development environment used to administrate and manage a Microsoft SQL Server. By using this tool, our backend developers could create tables within the code and use the query editor in SSMS 18 to write and execute SQL queries to see that the information in the database was correct. The was also used in the early stage of the development process, to find sources to for example marts in order to check if our endpoint for finding all information about an unique mart worked.</div></td>
                        <td class='correction'><div class='content'>- In the sentence "There are no problems with connecting the application to frontend and other external systems such as Azure", "frontend" should be corrected to "the frontend".

- In the sentence "To use swagger, we had to authenticate with our Intility.", "Intility" should be capitalized as "Intility".

- In the sentence "The current application takes some time to load because it has a lot of information, therefore it is important to choose a programming language which runs fast and efficiently.", a comma should be added after "information" to make it "because it has a lot of information, therefore...".

- In the sentence "There are some teams at Intility that are using python, but compared to .NET, python is not that good at handling high-performance computing, and it is not the best language for processing substantial amounts of data. ().", the sentence does not seem to end well, and the position of the period does not seem correct. 

- In the sentence "Golang is a familiar language which is like .NET, but it is a simpler language and has fewer features than .NET.", "simpler" should be corrected to "a simpler" since we are comparing Go to .NET.

- In the sentence "A reason to decide on .NET instead of Java is because the development team are more familiar with Visual Studio as an IDE compared to IntelliJ which is the most used IDE for Java.", "are" should be corrected to "is" since "development team" is a singular noun. 

- In the sentence "This topic will be discussed in chapter 6.1.3 (). ()", the second set of parentheses should be removed.

- The sentence "In the development phase this is a useful tool to keep the cost of change low." can be improved by adding a transitional phrase such as "Moreover" at the beginning of the sentence.

- In the sentence "It was also the preferred from Intility that we used either of the two compilers in order to make it as easy as possible to integrate the application with Intility’s existing applications.", "preferred" should be corrected to "preference" to make the sentence grammatically correct.

- In the sentence "The was also used in the early stage of the development process, to find sources to for example marts in order to check if our endpoint for finding all information about an unique mart worked.", "The" should be removed.

Corrected paragraph: 

Backend

At the start of this project, the development team chose to use .NET for the backend development, which is an object-oriented programming language designed by Microsoft. .NET is a great language to use with Web Api support and is perfect for this assignment.

There are no problems with connecting the application to the frontend and other external systems such as Azure. In one of our previous courses called "Integrasjonsprosjekt", we struggled a little bit with connecting the frontend to the backend and making the website safe enough to have HTTPS. Fortunately, this was not a problem we encountered with this project due to our better choice of backend technologies.

One reason to use .NET is how easily it can be integrated with Swagger, which we have used to manually test the endpoints. The figure xxxxx in chapter 5.2.1 shows an example of how a controller for the endpoints looks like. To use Swagger, we had to authenticate with our Intility. The backend Swagger was running at all times with the code pushed to Gitlab, but we could also run the backend locally and check if the code worked as intended with localhost Swagger. This was to ensure that the code pushed to Gitlab could run without any problems.

According to https://ukad-group.com/blog/aspnet-core-8-pros-and-cons/, it is important to choose a programming language that runs fast and efficiently since the current application takes some time to load because it has a lot of information. As mentioned in chapter 3.7.1 and in chapter 3.7.2, our goals were to decrease the loading time for both the dbt docs and for the lineage graph. A possible solution to this was a fast backend that could cache large amounts of data, ensuring that the load time would be faster after the first time opening the website.

Alternatives to .NET:

Python is an alternative to .NET that the development team could have used. There are some teams at Intility that are using Python, but compared to .NET, Python is not as good at handling high-performance computing, and it is not the best language for processing substantial amounts of data.

Golang is like .NET, but it is a simpler language and has fewer features than .NET. Features like LINQ and pattern matching are not supported in Go. According to https://cshark.com/blog/c-vs-go-which-is-better-for-your-next-application/, LINQ is a fantastic addition to a language that supplies a consistent query experience to relational databases.

Java is one of the most widely used programming languages for development. For instance, Java can run on any operating system with its compilers and Java Runtime Environment. That does not apply to .NET, which only focuses on Windows users. However, the development team chose .NET instead of Java because they were more familiar with Visual Studio as an IDE compared to IntelliJ, which is the most used IDE for Java.

All three languages are exceptional for web and cross-platform development, but we did not find any other reason to why we should deviate from the standard Intility backend language.

Manually testing the endpoints:

In order to test and develop the backend endpoints before trying them on the frontend, the development team used Swagger. Additionally, Swagger creates documentation, example requests, and data from the code, which is useful in the development phase to keep the cost of change low. Although the development team could have used Postman for manual endpoint testing, Swagger is well integrated with the verification tokens (bearer tokens) needed to get the correct response from the database.

Backend compilers:

The compilers used for this project were Visual Studio Code and Visual Studio 2022. These compilers were chosen because they are preferred by Intility to make it easy as possible to integrate the application with its existing applications. Moreover, Visual Studio is more familiar to the development team.

Backend testing tool:

xUnit

Database tool:

The database tool used for this assignment is Microsoft SQL Server Management Studio 18, which is a graphical integrated development environment used to administrate and manage a Microsoft SQL Server. By using this tool, our backend developers could create tables within the code and use the query editor in SSMS 18 to write and execute SQL queries to verify that the information in the database was correct. We also used it in the early stage of the development process to find sources, such as marts, to check if our endpoint for finding all information about a unique mart worked.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Frontend

The frontend tools used in this project is Typescript with React. The main reason behind this combination, is that Intility preferred that they were the tools for the frontend. In the two following chapters, it will discussed why the technologies did not deviate from the standard Intility tools and compare the choice of tools with alternatives.

Typescript vs Javascript



In the development of our project, we utilized TypeScript, a superset of JavaScript, which is strongly typed and adds additional features to the language. Although we could have used JavaScript for the same purpose, the decision to use TypeScript was recommended by Intility, due to its numerous benefits. TypeScript improves code readability and maintainability, enhanced error-checking and debugging capabilities, and increased code scalability. With TypeScript, the code is easier to read and understand as the type definitions make it clear what data types are being used. Additionally, it catches errors before the code is run, making debugging easier and reducing the time spent fixing issues. TypeScript also scales better for larger projects, as it allows for better code organization and modularization. Overall, the use of TypeScript was a wise decision as it enabled us to develop a more robust and maintainable codebase.







React vs Vuejs



On a previous project Vue.js was chosen as the framework. While Vue.js is also a great choice for building web applications, we ultimately decided to use React for this project. Both Vue.js and React are amazing frameworks for building web applications and have a lot of similarities. However, there are some differences between the two that has led us to use it for this project. One major factor was React’s performance, which is optimized for building large-scale and complex applications. Additionally, React’s popularity and large developer community make it easier to find resources and support. Since its used by developers in Intility they provided us with a course in React and have also helped when needed. Another reason why we chose React is its flexibility and modularity, which allows us to easily integrate it with other libraries and tools as needed. Overall, the decision to use React for this project was based on a careful evaluation of its strengths and our projects requirements.





Frontend testing tool





Jest

Bifrost



Bifrost is an Intility design system which is a useful tool for developers to quickly develop new projects. All Initility’s site use this design system in order to make the interface of the websites look the same. The Bifrost library consists of different models and examples for front-end development. The front-end team can look at the Bifrost website and use components from the website in order to develop their own website. The models from Bifrost are not tailored to each project, so in some cases modifications to the existing models are needed.

</div></td>
                        <td class='correction'><div class='content'>In the first paragraph, there is a missing word in this sentence: "In the two following chapters, it will discussed why the technologies did not deviate from the standard Intility tools and compare the choice of tools with alternatives." It should be corrected to "In the two following chapters, it will be discussed why the technologies did not deviate from the standard Intility tools and how they compare to alternative tools."

In the second paragraph, the first sentence doesn't have proper subject-verb agreement. It should be corrected to "In the development of our project, we utilized TypeScript, a superset of JavaScript, which is strongly typed and adds additional features to the language."

In the third paragraph, the first sentence lacks punctuation. It should be corrected to "Jest and Bifrost are the testing tools used in this project."

Other than these corrections, the text looks good!

lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Communication and helper tools

Gitlab



Gitlab has been the version control tool for this project. There are also other similar tools such as GitHub and Bitbucket, but the group have not been using them throughout the bachelor’s degree. At the beginning of the project, the group set up a pipeline for both the frontend and backend folder and preset some rules on Gitlab such that it is not possible to commit to the main branch.

At the start of the project, the group had a Gitlab workshop with an employee in Intility, which thought us to set up some necessary configurations like CI/CD for the pipelines. It was a useful workshop where the group learned more about best practices with naming conventions, usage of different branches and merging.

See meeting minutes xxxx in appendix (if there are any)



Communication and documentation



Teams

Teams have been the main platform for meetings and communication with both Intility and the bachelor guidance counselor. There are several other options like Google meet, but Teams is what the development team are the most familiar with and it provides a lot of different functionality for scheduling meetings and asking questions to other employees in Intility. Slack is also a tool used to contact other employees about questions related to the project.

Discord

Discord has been the main platform for communication within the group. In Discord, it is possible to create a Discord server, with different text channels for various categories. This way, there have been stored links, meeting minutes and other important material related to the bachelor project.

Jira

The development team had a biweekly sprint period where they had several issues in the sprint. At the beginning of the process, there was an attempt to use issue tracking in Gitlab which is the standard issue tracking tool within Intility. However, the group found it easier to keep track of their issues using Jira over GitLab. The backlog is another feature provided in Jira. The backlog is a list of issues where the developer could select additional issues if there was any time left. Jira is an exceptional tool for this purpose.

</div></td>
                        <td class='correction'><div class='content'>Gitlab:

- "but the group have not been using them" should be "but the group has not been using them"
- "the group set up a pipeline for both the frontend and backend folder" could be improved by specifying what the pipeline does exactly
- "such that it is not possible to commit to the main branch" could be rephrased as "making it impossible to commit directly to the main branch"

Communication and documentation:

lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Implementation

Write about the whole process, how things are made and why

Introduction with the order of operations

Write about all the different pages implemented with screenshots</div></td>
                        <td class='correction'><div class='content'>There are several grammar and structural issues with the given text:

1. The paragraph lacks coherence and doesn't provide a clear picture of the message that the writer wants to convey. 

2. The heading "Implementation" is too broad and doesn't reflect the specific context of the report. 

3. The paragraph lacks details and specific information. 

4. There are no errors with regards to grammar and spelling. 

Here's how I'll suggest to rephrase the paragraph:

"Literature on our data platform manager has been thoroughly researched and written for the benefit of educators, evaluators, and students. In accordance, this report provides a systematic order of operations of the implementation process, from inception to completion. 

The report discusses the different pages, their functionalities and the development process behind them. Accompanied by snapshots, this comprehensive and informative resource provides insights into the integration of the data platform." 

Hope this helps!</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Deployment</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>API</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Database

The database was set up by Intility, but managed and populated with functions created by us. All the information is either added manually by the user of the application or added automatically from the manifest.json file. Example of information added manually are the business systems or the business glossaries.

Purpose

Design

Data Entry and Managements

Queries and Reports

Data Security and Backup

Checking for correct input before database is populated

When sending requests from frontend to the database, there are functions checking the input fields. If the input is wrong, the request would fail and give an error message to the user. This will make sure that the user will try to fill in the input again, but with only the allowed characters.



There are still possible so send request through tools like Swagger or Postman to avoid this input validation. To avoid this problem, we had to create input validation function in backend as well to check for invalid input. This is done by precompiling the regex, then checking the input fields with the allowed characters in the regex. The reason behind precompiling the regex was to follow best practice when working with regex in order to have as fast as possible execution of the program. A cached regex can be reused, and this will be faster than compiling the same expression repeatedly.

User Interface

Future Enhancements

</div></td>
                        <td class='correction'><div class='content'>- In the first sentence, change "functions" to "functionality" to make it clearer that functions were created, not just basic functions. 
- In the second and third sentences, combine them to better structure the paragraph. 

Corrected Paragraph:

The database was set up by Intility, but we managed and populated it with functionality that we created. All information is added manually by the application user or automatically from the manifest.json file, such as business systems or business glossaries. When sending requests from the frontend to the database, functions check the input fields to ensure that only allowed characters are used, and if the input is incorrect, an error message is shown to the user. However, it's still possible to send requests through tools like Swagger or Postman, so input validation functions were created in the backend to check for invalid input using precompiled regex. Precompiling the regex allows for faster execution of the program and avoids repeatedly compiling the same expression. 

Comments: 
- The paragraph lacks a clear heading. Adding a heading such as "Input Validation" or "Database Management" would clarify the main topic. 
- The paragraph can benefit from using simple language to make it easier to read by people with limited technical background. 
- The paragraph can also benefit from stating why data security and backup, queries and reports, and user interface may be important in the context of the data platform. 

Lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Lineage graph

Displaying the lineage graph frontend was a major part of the assignment, and finishing it was a primary objective from the very beginning. It was important for Intility that the lineage was easy to use and user-friendly. A request from them, was that our lineage graph looked like the already existing lineage graph on the DBT docs site. They also wanted some extra features like Intility standardization (wcag) and earlier stages of the data jobs.

First, there were some sketching in Figma in order to have some visual on how there would be possible to create the function. It was a simple sketch, but it gave us a great understanding of



After the sketching, we had to find a way to create it on a website. The data science department tipped us that another department had create a similar graph as we had sketched out. The picture below was the inspiration we had when we started creating our own.





This is an example of the results of our lineage graph. The graph starts at a business system and finds all sources, stagings, marts and exposures. There are some similarities to the Network department’s lineage graph, but when the two pictures above are compared, it is easy to see that our graph is used for another purpose with less details and another way to display the nodes.

We wanted to create a graph which was easy to use and had clickable interactive functionality to display information. There are several interactive functionalities on the lineage graph. All the nodes are clickable and will display a drawer with basic information about the node, and it is a button within the drawer to display the full information. The “Fit view” button located in the top right corner of the screen will fit the screen back to default if the user has been zooming. As mentioned, zooming the graph is also an option in order to make larger graphs more readable. It is also possible to move all the nodes around without losing the relations. The line between the nodes will not disappear if a node is moved.



When the ‘See full info’ button is pressed, the website will be redirected to a page with more detailed information about the type. The two pictures below are the information that will be displayed.





There are different WCAG colors for the different types which are shown on the figure xxx above. By doing this, the user could find out the relation types in the graph. Look at the table below for the color codes.



We are extremely proud of how the lineage graph ended up looking. As mentioned, we have created a good looking, easily readable and interactive graph within the Intility standard. The graph is faster and more effective compared to the existing graph as DBT docs, which was one of our goals in the chapter 3.7.2 ().

Innovative way to solve this task, good looking frontend and connecting business systems to a source

In the next two chapters, we will break down how the frontend and backend are programmed in order to display the graph shown on the previous figures in this chapter.

Lineage graph frontend



With little to no experience with visualizing graphs, this quickly proved to be a challenge. Luckily, there is a React component called React Flow, which was made for this purpose. After thorough research, the front-end team displayed a simple graph to the screen. Navigation throughout the graph and moving the nodes are part of the react flow component out-of-the-box.

The next major challenge was finding a way to arrange the nodes correctly in a tree shape for easy visualization and understanding. To accomplish this, the group utilized a package called “The Eclipse Layout Kernel” (ELK). This package introduces a collection of layout algorithms to simplify the process of getting the initial diagram layout right.

After the diagram showed the correct nodes and edges in the right position, the next issue was making the nodes interactive, to display a drawer of basic information whenever a node is clicked.

Lineage graph backend



There were a lot of research in order to be able to display the whole lineage graph with different nodes and information for each node. The solution became to create recursive functions. This knowledge was taught to us in the Algorithm methods earlier this bachelor’s degree.









The ‘SearchParents’ and ‘SearchChilds’ functions, are looping through to find all relations. If there are any relations, an id consisting of an “e-“ and the combination of the id and the parent or child. The “e” stands for edge. When the edges are added, the function will run recursive again to find all the relations.

The two functions mentioned above is together in the ‘FetchRelations’ function which is used by the controller whenever a call to the endpoint is made.

These functions took a lot of time to create, and we were very proud of how it turned out. There are complex functions which needs to go through all nodes and find their child nodes and parent nodes. A node can have many nested children, so the function needed to continue to check the children’s nodes for even more children.</div></td>
                        <td class='correction'><div class='content'>The first sentence in the paragraph is missing a verb. Suggested corrected sentence: "Displaying the lineage graph on the frontend was a major part of the assignment, and finishing it was a primary objective from the very beginning." 

In the sentence "There were some sketching in Figma...", 'sketching' should be changed to 'sketches'. 

In the sentence "After the diagram showed the correct nodes and edges in the right position, the next issue was making the nodes interactive, to display a drawer of basic information whenever a node is clicked.", the phrase "to display a drawer of basic information whenever a node is clicked" should be changed to "that displayed a drawer of basic information whenever a node was clicked."

In the sentence "There were a lot of research in order to be able to display the whole lineage graph with different nodes and information for each node.", 'research' should be changed to 'researching.'

In the sentence "These functions took a lot of time to create, and we were very proud of how it turned out.", 'it' is vague and should be changed to 'the functions.' 

In the sentence "A node can have many nested children, so the function needed to continue to check the children’s nodes for even more children.", 'children's' should be changed to 'children.' 

Overall, the paragraph is well-written, informative, and structured. No major changes are necessary. 

lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Changelog</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Backend Testing</div></td>
                        <td class='correction'><div class='content'>LGTM.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Frontend Testing



For frontend testing we performed unit testing.  We used the framework Vitest for testing which is excellent for unit testing, and a fast framework that includes additional features from the jest framework. For frontend we have a total of 6 tests. These are tests for testing the linear search function that we made. Including a function used inside the search function that removes special characters. We tested the search function as it is the function which is most likely to have flaws and issues. Doing tests on it we figured out that some of the functionality didn’t work as intended and we had to change the function accordingly.

RemoveSpecialCharacters function:



This is a unit test for a function removing special characters from a string. It sets the string to be “hello-world!”, and then the expected result should be “helloworld” as it removes the dash (-) and the exclamation mark (!) from the string. The test succeeds if the removeSpecialCharacters can remove special characters and equals the expected result. The removeSpecialCharacters function can be viewed here: link

simulateSearch function:



For the simulateSearch function we did 5 tests. The tests are based on filtering, sorting and loading. This function simulates a linear search and returns all the data assets matching the search. The function is explained in this chapter: link

Mock data:



Test 1 (filters and sorts the search results correctly when value is not empty and does not contain an underscore)



The first unit test filters and sorts the results based on the string “test”. This should then print out all results including that word. It then simulates the search, starts a timer and sets loading to false and then checking that the search function is returning the expected results.

Test 2 (filters and sorts the search results correctly when value is not empty and contains an underscore)



Todo: explanation



Test 3 (sets search results to an empty array when value is empty)



Todo: explanation



Test 4 (sets loading state to true when simulateSearch is called)



Todo: explanation

Test 5 (sets loading state to false after a 1000ms delay)



Todo: explanation

</div></td>
                        <td class='correction'><div class='content'>lgtm</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>User testing</div></td>
                        <td class='correction'><div class='content'>This heading is fine as it is. It's informative and concise. Therefore, it is good to go.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Scrum

The Scrum process consisted of sprint review, sprint retrospective and sprint planning. The three parts were discussed and planned in the scrum meetings. At first, there was a sprint period of one week, but it increased to two weeks due to not having enough time to solve the more complex issues. When there were shorter sprint periods, the group did not create enough issues due to underestimating the workflow. With longer sprints, there were trouble-free to have complex issues which could take a lot more time than expected. The meetings with both Intility and the bachelor guidance consultant were primarily every week. The group tried also to have daily stand-up meetings when there was enough time and need to conduct a meeting.</div></td>
                        <td class='correction'><div class='content'>The Scrum process consists of sprint review, sprint retrospective, and sprint planning. These three parts are discussed and planned during the Scrum meetings. Initially, there was a sprint period of one week, but it was increased to two weeks due to not having enough time to solve more complex issues. When there were shorter sprint periods, the group did not create enough issues due to underestimating the workflow. With longer sprints, there were fewer issues, but they were more complex and could take a lot more time than expected. Meetings with both Intility and the bachelor guidance consultant were primarily held every week. The group also tried to have daily stand-up meetings when there was enough time and a need to conduct a meeting.

Comment: 
- "Consisted of sprint review" should be changed to "consists of sprint review"
- "But it increased" can be changed to "However, it was increased"
- "Trouble-free" is not the right word, maybe "fewer issues" would be better.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Jira

As mentioned earlier in this report, the development team used Jira to keep track of their issues. The group together had the responsibility to create enough issues for each member. All the issues had an issue type, and each issue was moved to the in-progress section when a group member started with the issue. The group member assigned the issue to themself, in order to not have more group members working on the same issue. It happened that the development team did not manage to finish all the issues. The reasons why that happened were discussed in the sprint retrospective part of the scrum meetings and the issues got moved to the next sprint.

Prioritizing the issues and talk about the order of the issues was important. This was not a problem, due to the good communication within the group. There were not any critical parts of this process, because the issues were often added to the sprint board after the sprint started. The reason the group decided to have this practice with the issues is because their features always appeared as the development progressed.</div></td>
                        <td class='correction'><div class='content'>As mentioned earlier in this report, the development team used Jira to keep track of their issues. The group was responsible for creating enough issues for each member. Each issue had a type assigned, and when a group member started with the issue, it was moved to the "in-progress" section. The group member then assigned the issue to themselves to avoid having multiple members working on the same issue. However, the development team was unable to complete all issues, as discussed in the sprint retrospective during the scrum meetings. These issues were then moved to the next sprint.

Prioritizing and discussing the order of the issues was important but not a problem, thanks to good communication in the group. There weren't any critical issues with this process, as the issues were frequently added to the sprint board during the sprint as features emerged. The group decided to implement this practice with the issues because the features appeared as the development progressed.

Comments: The paragraph had some grammar and sentence structure errors, in which some words needed to be changed. Ensure to proofread the text and punctuate the correct words.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Issue types

As mentioned above, there were different issue types. The most used was ‘task,’ which was used for all the regular features on the application. Whenever issues related to bugs were created, they were set to bug. The ‘report and models’ type was related to the project plan, the bachelor report and other documentation. The last type that frequently was used was ‘testing,’ related to the testing both frontend, backend, and the user tests. There is also a predefined story issue type in Jira, but there are no issues that had this type.

Having different issue types made it straightforward to see what the issue was about.



</div></td>
                        <td class='correction'><div class='content'>Lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Meetings with Intility

The development team had weekly syncs with Intility. There were mainly two representatives from Intility. One of them handled all the technical questions related to the assignment, and the other was responsible for the functionality. It also happened that five representatives from the team attended the user test(s). It was set aside one hour for every meeting, and it was scheduled on Friday, but it also happened that the meetings got scheduled for Tuesday instead. The motive behind these meetings, was to ask questions related to the task both if the group was struggling with some code problems or if there were any questions about how the application should look. It was important for the group to make the application as Intility requested, because then they could keep working on the application afterwards.</div></td>
                        <td class='correction'><div class='content'>The paragraph seems to be grammatically correct, but the sentences are too long and confusing. Here are the improvements that can be made:

- The development team had weekly syncs with Intility with two representatives: one technical and another responsible for functionality. Five team members attended user tests.
- Meetings were scheduled for an hour on Fridays but sometimes on Tuesdays. These meetings aimed to ask questions about the task or clarify requirements.
- It was essential for the team to meet Intility's requests to keep working on the application.

Although the paragraph is technically correct, it could be better structured and clearer.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Meetings with bachelor guidance consultant

A Status meeting with Johanna Johansen was planned every Wednesday at 13.30. There was one in the group which handled sending a status report to the bachelor guidance consultant. The focus of the meetings was feedback on the report and other relevant work at that given sprint period. Getting feedback on the report along the way, improved the workflow. After the feedback, the group had a meeting and talked about what they needed to refine. The group also got a clear indication on what they needed to include in the report in order to get their wanted grade.

See appendix xxx for examples of meeting minutes.</div></td>
                        <td class='correction'><div class='content'>There are a few minor corrections in this paragraph:

"A status meeting with Johanna Johansen was planned every Wednesday at 13:30. **One member** of the group **was responsible for** sending a status report to the bachelor guidance consultant. The focus of the meetings was feedback on the report and other relevant work **during** that given sprint period. Getting feedback on the report **during** the way improved the workflow. After the feedback, the group had a meeting and talked about what they needed to refine. The group also received clear indications **of** what they needed to include in the report to get their **desired** grade.

Lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Internal meetings

The group had several meetings when it was required. There were often extra group meetings right after the meetings with Intility and the bachelor guidance counselor. This was to discuss the notes from the meetings and talk about any further improvements. The biweekly scheduled meeting was where the group had the scrum meetings and discussed the previous sprint and the upcoming sprint. The available time and main goal of the upcoming sprint were major talking points, and the group created the necessary issues to reach their goal.

See appendix xxx for examples of the sprint planning meetings.

It was held daily standup meetings, where the group talked short about what they planned to work on that day. By doing so, all the group members were up to up to date on everyone's progress and everyone knew what they should work on. It happened that there were not enough issues for everyone. In that case, the group extended the standup meetings in order to talk about further issues.

</div></td>
                        <td class='correction'><div class='content'>Internal Meetings

The group had several required meetings, and there were often additional group meetings right after the meetings with Intility and the bachelor guidance counselor. The purpose was to discuss notes from the meetings and identify opportunities for further improvement. The biweekly scheduled meeting was where the group held scrum meetings and discussed the previous and upcoming sprints. Key discussion points included available time and the goals for the upcoming sprint, and the group created the necessary tasks to reach their objectives.

For examples of the sprint planning meetings, see Appendix xxx.

The group also held daily stand-up meetings to discuss plans for the day. This allowed all group members to stay up to date on each other's progress and be aware of what they were working on. On occasion, there were not enough tasks for everyone, and in those cases, the group extended the stand-up meetings to identify and discuss additional tasks. 

Comments: 
- Clarify what are the biweekly scheduled meetings for (e.g. scrum meetings)
- Instead of using "further improvements," use "identify opportunities for further improvement" to clarify the purpose of the meetings.
- Use specific terminology when referring to tasks, issues, or sprints for consistent language.
- "Upcoming sprint" should be plural as the group talks about multiple upcoming sprints.
- Use "tasks" instead of "issues" to describe what is created in the biweekly meetings.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Work environment

At the start of the project the group was introduced to the office and the different departments within Intility. All group members got their own designated work spot with necessary equipment like monitors, headset, mouse, and keyboard. They also received laptops to be used for everything related to the project and the company.

Intility’s offices are located in Oslo, and therefore the group members were unable to travel there daily from Gjøvik and Lillehammer. The commute takes about two hours each way by public transport. As a solution, the company sometimes offered the students to stay in their commute apartments to attend the office physically several days in a row. The expenses related to the trips were also covered by Intility.

An effect of the physical presence in the office was a better relationship and collaboration with the client, and especially the data science department. The work spots were located right by data science, which led to seamless communication and assistance with the task.</div></td>
                        <td class='correction'><div class='content'>Lgtm.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>What we learned working for Intility

Working for Intility have been a period with a lot of learning and we would not be without. It was a great experience to have a try on how it works out in a real company before we all eventually will start working like this every day.

As mentioned earlier in this report, there were set up different workshops at the start of the bachelor’s degree. This was to make sure that we were familiar with all the tools that we were familiar with all the tools needed for this project. It was also important that we had an understand of how Intility as a company did certain parts of their workday. In the following chapter, there will be discussed about what we have learned working for Intility.

(Et kapittel per punkt!)

Usage of git with branches and best practice commits

Continuous integration and continuous delivery

At the begging of our period at Intility, there were several workshops that they wanted us to attend to. The workshops were about how the different departments worked and what they could help us with, the tools Intility uses for their application and best practices at Intility. There were a lot of new information to learn, and we were told that there was not expected that it was possible for us to learn everything with our short time at Intility. These workshops made the development process a lot easier, because we were more familiar with the tools and the different departments.

Working in team is something that the group was familiar with before the bachelor’s project, but working in a larger team with more resources and the option to get help across different teams was not familiar. When there were any questions related to the development process, we were given the contact information to the employees at Intility with the most knowledge regarding our problem. This made it possible for us to develop as much as we did within the timeframe, because we got the needed help if we were stuck and could not find a solution.

Creating a product on demand was something new for us. Throughout the previous courses, the larger assignments have not been strictly defined and a with a free approach on how to solve the task. For this project, we been having weekly meetings with Intility in order to meet their needs with the project that we develop for them. It is worth mentioning that the assignment has been very open, and we have decided a lot based on the time limits and what we were comfortable to create.

Working for meeting the need of Intility have been a process that we learned a lot from. In chapter 8.3 (), you can read more about how the user tests was done at some Intility employees. User testing a product is something that the previous courses have barely thought us. It was very helpful to get some additional reading materials from our bachelor guidance counselor. After the user tests was done, there were a lot to redo in order to meet the need of Intility. This have been discussed more in chapter 8.3 ().

</div></td>
                        <td class='correction'><div class='content'>Working for Intility has been a period of extensive learning that we would not have been without. It was a great experience to have a try on how it works out in a real company before we eventually start working like this every day.

As mentioned earlier in this report, there were workshops set up at the start of the bachelor’s degree to ensure that we were familiar with all the tools needed for this project. It was also important that we understood how Intility as a company carries out certain parts of their workday. In the following subsections, we will discuss what we have learned working for Intility focusing on specific topics: 

1. Usage of Git with branches and best practice commits 
2. Continuous integration and continuous delivery 

At the beginning of our period at Intility, several workshops were conducted to educate us on how different departments worked and what tools they used for their applications. We were informed of best practices at Intility, and a wealth of new information was passed across to us. While it wasn't expected that we learned everything within our short-time, these workshops made the development process more straightforward as we were familiar with the tools used, and the different departments.

Although working in teams is something the group was familiar with before the bachelor’s project, working in a larger team with more resources and the option to get help across different teams was new to us. Whenever there were any questions related to the development process, we were given contact information for employees at Intility with the most knowledge regarding our problem. This made it possible for us to develop as much as we did within the timeframe because we got the necessary help if we were stuck and could not find a solution.

Creating a product to meet the demands of a client was novel to us. In previous courses, the larger assignments have been less defined, giving a free approach to solve the task. For this project, we had weekly meetings with Intility to meet their specific objectives for the product we were developing for them. It is worth mentioning that the assignment has been very open, and we have decided a lot based on the time limits and what we were comfortable to create.

Working to meet the needs of Intility has been a process whereby we have learned a great deal. In chapter 8.3, you can read more about how user testing was conducted with Intility employees. User testing a product is something the previous courses barely taught. It was beneficial to get some additional reading materials from our bachelor guidance counselor. After the user tests were done, there was a great deal to redo to meet the needs of the users. This is discussed in more detail in chapter 8.3.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Results

Write about if we met the goals</div></td>
                        <td class='correction'><div class='content'>I'm sorry, there is no context provided for me to make necessary corrections. Please provide me with the full paragraph or text so I can assist you better.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Process

The development process was very educational, and the group learned a lot about how to work project-based in the industry. However, if the group were to carry out the project again, they would make some changes.

Primarily they would choose to spend more time on the planning phase, before starting to implement functionality into the application. To utilize scrum efficiently, the group would start by composing a backlog of all known issues for the project's duration. This would help contain a better overall flow throughout the development. 
Another aspect of the task that could have been improved was communication with the client and gaining a better understanding between the group and the client about specifications. The requirements given at the start of the process did not fully correlate with what the client really wanted, which led to some changes being introduced midway through the development. If the group set expectations for a more concise set of requirements, this could have been avoided.</div></td>
                        <td class='correction'><div class='content'>The paragraph seems well-written, with no major grammatical errors, and it conveys its points effectively. However, here are a few minor changes that can be made to make it more polished:

"The group learned a lot about how to work on a project-based model in the industry during the development process. However, if they were to carry out the project again, they would have made some changes. Firstly, they would allocate more time towards the planning phase before starting with the implementation of the application functionalities. In order to utilize Scrum efficiently, the group would start by composing a backlog of all known issues for the project's duration, which would help maintain a better overall flow throughout the development. Another aspect that could have been improved was communication with the client, obtaining a better understanding between the group and the client about requirements. The requirements given at the start of the process did not fully correlate with what the client really wanted, which led to the introduction of some changes midway through the development. If the group had set expectations for a more concise set of requirements, these changes could have been avoided."

Overall, the paragraph is already pretty good, but the above changes just make the points come across more clearly and eloquently.</div></td>
                    </tr>
                
                    <tr>
                        <td><div class='content'>Future development

As mentioned in the introduction, part of why Intility wanted their own data platform manager application was to have the opportunity to customize and improve it further. During several meetings with the data science department, plenty of unique and useful features have been discussed. Not all these features were implemented during this bachelor project, mainly because of limited time.

The main feature discussed, and possibly the most useful, is to make the data platform manager more interactive by adding an option to refresh a report. This would be very useful for anyone using the data within Intility, and potentially also for Intility’s customers. Upon a button click, the data platform manager backend would trigger a refresh on every model a given report is dependent on. Starting from the business system, and going through every source, staging, mart and exposure the selected report depends on. This would provide updated data in seconds, without the hassle of manually finding every model needing an update.

Another useful feature would be an admin page. Giving only the employees within the data science department access to certain functionality like creating and editing business systems, changing the glossary or linking a source to a business system. These features are currently available for all users of the data platform manager, as the group does not have the privileges to integrate the roles.

















References

Firesmith, D. (2020, January) Engineering System Resilience Requirements. Carnegie Mellon University. https://insights.sei.cmu.edu/

Barcheski, J & Collis, S (2023, March) Dbt (Data Build Tool) Overview: What is dbt and What Can It Do for My Data Pipeline?
	https://www.analytics8.com/blog/dbt-overview-what-is-dbt-and-what-can-it-do-for-my-data-pipeline/

Gardner, M. (2021). Data Science for Beginners: An Introduction to Big Data, Analytics and Machine Learning. The Data Science Handbook.

Kelleher, J. D., & Tierney, B. (2018). Data Science: An Introduction. CRC Press.



SQL Server Management Studio (SSMS) - Overview:

SQL Server Management Studio (SSMS) - Tutorial:

</div></td>
                        <td class='correction'><div class='content'>The paragraph looks good, but there's a minor grammatical error -- "Starting from the business system and going through every source, staging, mart, and exposure the selected report depends on" should have commas after 'source' and 'exposure' to separate them from 'staging' and 'mart'. So the corrected sentence is "Starting from the business system and going through every source, staging, mart, and exposure, the selected report depends on."</div></td>
                    </tr>
                </table></body></html>